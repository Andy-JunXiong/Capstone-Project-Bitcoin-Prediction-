{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multilayer Neural Network Classifier.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/QuangTrungNguyen/Bitcoin-predictions-and-visualisations-capstone/blob/master/Multilayer_Neural_Network_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "6Zy_zfDMpwgH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oHrXQovup29f",
        "colab_type": "code",
        "outputId": "096895b9-908e-4ae0-ad69-54e1e8c5d1ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Test if GPU is active\n",
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "kQ69_1W9kIVE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Import Libraries##"
      ]
    },
    {
      "metadata": {
        "id": "GDAaanDsqR-y",
        "colab_type": "code",
        "outputId": "7d33fc56-88dc-4af3-e48d-acfc8dff9381",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from time import time\n",
        "from random import randint\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, GRU, Dropout,Activation\n",
        "from keras.optimizers import SGD, RMSprop, Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras import initializers\n",
        "from matplotlib import pyplot\n",
        "from datetime import datetime\n",
        "import sklearn.model_selection\n",
        "import plotly.offline as py\n",
        "import plotly.graph_objs as go\n",
        "import keras\n",
        "from sklearn.pipeline import Pipeline\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "py.init_notebook_mode(connected=True)\n",
        "%matplotlib inline\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "dBDlbAUPkOEh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Import Dataset##"
      ]
    },
    {
      "metadata": {
        "id": "qoGC5QCBqSp8",
        "colab_type": "code",
        "outputId": "7739c7bd-728a-4858-d844-ec3abc3844a8",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "# PyDrive reference:\n",
        "# https://gsuitedevs.github.io/PyDrive/docs/build/html/index.html\n",
        "\n",
        "# PyDrive reference:\n",
        "# https://gsuitedevs.github.io/PyDrive/docs/build/html/index.html\n",
        "\n",
        "# Read data\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "\n",
        "# Read the dataset and record the running time\n",
        "time_1 = time()\n",
        "dataset = pd.read_csv(\"BTC_15min.csv\", sep = \",\", parse_dates=[0], dayfirst = True)\n",
        "time_2 = time()\n",
        "print('read data cost '+ str(time_2 - time_1)+' second')\n",
        "\n",
        "random.seed(42)\n",
        "\n",
        "X = dataset.iloc[:, 1:-1]\n",
        "y = dataset.iloc[:, -1]\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-73c39d9a-9bdd-4110-b982-1b6f8b883cb9\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-73c39d9a-9bdd-4110-b982-1b6f8b883cb9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving BTC_15min.csv to BTC_15min (1).csv\n",
            "User uploaded file \"BTC_15min.csv\" with length 4683361 bytes\n",
            "read data cost 0.09671425819396973 second\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SVYGIKiGkUoY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model Training and Testing##"
      ]
    },
    {
      "metadata": {
        "id": "qmpytaZGdpoD",
        "colab_type": "code",
        "outputId": "d8d70d1b-6cc8-42f3-98a4-8af1b4bca36d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 18436
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Split train and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=(1))\n",
        "\n",
        "# Standardise data\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "# Perform Principal Component Analysis \n",
        "from sklearn.decomposition import PCA\n",
        "pca=PCA(n_components=None)\n",
        "X_train=pca.fit_transform(X_train)\n",
        "X_test=pca.transform(X_test)\n",
        "explained_variace=pca.explained_variance_ratio_\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers.core import Dropout\n",
        "\n",
        "# Train classifier\n",
        "classifier = Sequential()\n",
        "classifier.add(Dense(units = 128,kernel_initializer='normal', activation = 'relu', input_dim = X_train.shape[1]))\n",
        "classifier.add(Dropout(0.25))\n",
        "classifier.add(Dense(units = 64, kernel_initializer='normal',activation = 'relu'))\n",
        "classifier.add(Dense(units = 32, kernel_initializer='normal',activation = 'relu'))\n",
        "classifier.add(Dense(units = 16, kernel_initializer='normal',activation = 'relu'))\n",
        "classifier.add(Dense(units = 8, kernel_initializer='normal',activation = 'relu'))\n",
        "classifier.add(Dense(units = 1, kernel_initializer='normal',activation = 'sigmoid'))\n",
        "classifier.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "history=classifier.fit(X_train, y_train,validation_split=0.33, batch_size = 1000, epochs = 500)\n",
        "\n",
        "# Prediction\n",
        "y_pred = classifier.predict(X_test)\n",
        "y_pred=np.where(y_pred>0.5,1,0)\n",
        "\n",
        "# Confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm=confusion_matrix(y_test,y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "\n",
        "# Plot history for accuracy\n",
        "\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot history for loss\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test,y_pred)\n",
        "print(\"Test Accuracy: {:0.2f}\".format(accuracy))\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 9463 samples, validate on 4661 samples\n",
            "Epoch 1/500\n",
            "9463/9463 [==============================] - 0s 52us/step - loss: 0.6931 - acc: 0.5076 - val_loss: 0.6931 - val_acc: 0.5113\n",
            "Epoch 2/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.6930 - acc: 0.5114 - val_loss: 0.6930 - val_acc: 0.5113\n",
            "Epoch 3/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.6930 - acc: 0.5114 - val_loss: 0.6929 - val_acc: 0.5113\n",
            "Epoch 4/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.6928 - acc: 0.5114 - val_loss: 0.6927 - val_acc: 0.5113\n",
            "Epoch 5/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.6925 - acc: 0.5114 - val_loss: 0.6921 - val_acc: 0.5113\n",
            "Epoch 6/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.6914 - acc: 0.5116 - val_loss: 0.6901 - val_acc: 0.5128\n",
            "Epoch 7/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.6880 - acc: 0.5499 - val_loss: 0.6841 - val_acc: 0.6121\n",
            "Epoch 8/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.6784 - acc: 0.6133 - val_loss: 0.6710 - val_acc: 0.6237\n",
            "Epoch 9/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.6629 - acc: 0.6200 - val_loss: 0.6593 - val_acc: 0.6237\n",
            "Epoch 10/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.6524 - acc: 0.6254 - val_loss: 0.6501 - val_acc: 0.6321\n",
            "Epoch 11/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.6440 - acc: 0.6330 - val_loss: 0.6397 - val_acc: 0.6432\n",
            "Epoch 12/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.6371 - acc: 0.6426 - val_loss: 0.6324 - val_acc: 0.6574\n",
            "Epoch 13/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.6298 - acc: 0.6504 - val_loss: 0.6233 - val_acc: 0.6681\n",
            "Epoch 14/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.6223 - acc: 0.6580 - val_loss: 0.6173 - val_acc: 0.6782\n",
            "Epoch 15/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.6172 - acc: 0.6595 - val_loss: 0.6131 - val_acc: 0.6711\n",
            "Epoch 16/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.6119 - acc: 0.6622 - val_loss: 0.6086 - val_acc: 0.6745\n",
            "Epoch 17/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.6030 - acc: 0.6728 - val_loss: 0.6073 - val_acc: 0.6681\n",
            "Epoch 18/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.6046 - acc: 0.6740 - val_loss: 0.5937 - val_acc: 0.6885\n",
            "Epoch 19/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.5951 - acc: 0.6819 - val_loss: 0.5883 - val_acc: 0.6898\n",
            "Epoch 20/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.5896 - acc: 0.6900 - val_loss: 0.5841 - val_acc: 0.7020\n",
            "Epoch 21/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.5804 - acc: 0.6941 - val_loss: 0.5802 - val_acc: 0.7050\n",
            "Epoch 22/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.5745 - acc: 0.6964 - val_loss: 0.5741 - val_acc: 0.7086\n",
            "Epoch 23/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.5711 - acc: 0.7031 - val_loss: 0.5658 - val_acc: 0.7138\n",
            "Epoch 24/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.5679 - acc: 0.7043 - val_loss: 0.5627 - val_acc: 0.7086\n",
            "Epoch 25/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.5619 - acc: 0.7099 - val_loss: 0.5557 - val_acc: 0.7211\n",
            "Epoch 26/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.5541 - acc: 0.7164 - val_loss: 0.5516 - val_acc: 0.7219\n",
            "Epoch 27/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.5459 - acc: 0.7238 - val_loss: 0.5467 - val_acc: 0.7329\n",
            "Epoch 28/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.5453 - acc: 0.7252 - val_loss: 0.5412 - val_acc: 0.7277\n",
            "Epoch 29/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.5341 - acc: 0.7343 - val_loss: 0.5354 - val_acc: 0.7333\n",
            "Epoch 30/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.5282 - acc: 0.7375 - val_loss: 0.5252 - val_acc: 0.7449\n",
            "Epoch 31/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.5242 - acc: 0.7392 - val_loss: 0.5137 - val_acc: 0.7466\n",
            "Epoch 32/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.5113 - acc: 0.7493 - val_loss: 0.5077 - val_acc: 0.7518\n",
            "Epoch 33/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.5112 - acc: 0.7527 - val_loss: 0.4980 - val_acc: 0.7651\n",
            "Epoch 34/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.5016 - acc: 0.7594 - val_loss: 0.4880 - val_acc: 0.7779\n",
            "Epoch 35/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.4953 - acc: 0.7583 - val_loss: 0.4831 - val_acc: 0.7713\n",
            "Epoch 36/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.4874 - acc: 0.7681 - val_loss: 0.4759 - val_acc: 0.7730\n",
            "Epoch 37/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.4850 - acc: 0.7654 - val_loss: 0.4661 - val_acc: 0.7820\n",
            "Epoch 38/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.4791 - acc: 0.7744 - val_loss: 0.4544 - val_acc: 0.7964\n",
            "Epoch 39/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.4738 - acc: 0.7757 - val_loss: 0.4493 - val_acc: 0.8013\n",
            "Epoch 40/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.4601 - acc: 0.7842 - val_loss: 0.4396 - val_acc: 0.8056\n",
            "Epoch 41/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.4531 - acc: 0.7896 - val_loss: 0.4344 - val_acc: 0.8131\n",
            "Epoch 42/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.4483 - acc: 0.7938 - val_loss: 0.4253 - val_acc: 0.8187\n",
            "Epoch 43/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.4414 - acc: 0.7971 - val_loss: 0.4135 - val_acc: 0.8256\n",
            "Epoch 44/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.4342 - acc: 0.8044 - val_loss: 0.4100 - val_acc: 0.8251\n",
            "Epoch 45/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.4338 - acc: 0.8057 - val_loss: 0.4169 - val_acc: 0.8136\n",
            "Epoch 46/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.4252 - acc: 0.8080 - val_loss: 0.3966 - val_acc: 0.8372\n",
            "Epoch 47/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.4159 - acc: 0.8119 - val_loss: 0.3998 - val_acc: 0.8277\n",
            "Epoch 48/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.4179 - acc: 0.8150 - val_loss: 0.3857 - val_acc: 0.8455\n",
            "Epoch 49/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.4137 - acc: 0.8135 - val_loss: 0.3904 - val_acc: 0.8384\n",
            "Epoch 50/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.4130 - acc: 0.8162 - val_loss: 0.3814 - val_acc: 0.8445\n",
            "Epoch 51/500\n",
            "9463/9463 [==============================] - 0s 13us/step - loss: 0.4062 - acc: 0.8168 - val_loss: 0.3772 - val_acc: 0.8492\n",
            "Epoch 52/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.3991 - acc: 0.8254 - val_loss: 0.3679 - val_acc: 0.8515\n",
            "Epoch 53/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.3881 - acc: 0.8297 - val_loss: 0.3813 - val_acc: 0.8380\n",
            "Epoch 54/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.3998 - acc: 0.8231 - val_loss: 0.3604 - val_acc: 0.8539\n",
            "Epoch 55/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.3911 - acc: 0.8320 - val_loss: 0.3592 - val_acc: 0.8550\n",
            "Epoch 56/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.3856 - acc: 0.8332 - val_loss: 0.3576 - val_acc: 0.8556\n",
            "Epoch 57/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.3663 - acc: 0.8435 - val_loss: 0.3542 - val_acc: 0.8569\n",
            "Epoch 58/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.3736 - acc: 0.8375 - val_loss: 0.3489 - val_acc: 0.8610\n",
            "Epoch 59/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.3701 - acc: 0.8404 - val_loss: 0.3408 - val_acc: 0.8646\n",
            "Epoch 60/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.3610 - acc: 0.8491 - val_loss: 0.3449 - val_acc: 0.8558\n",
            "Epoch 61/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.3612 - acc: 0.8454 - val_loss: 0.3369 - val_acc: 0.8642\n",
            "Epoch 62/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.3580 - acc: 0.8431 - val_loss: 0.3318 - val_acc: 0.8678\n",
            "Epoch 63/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.3522 - acc: 0.8525 - val_loss: 0.3364 - val_acc: 0.8620\n",
            "Epoch 64/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.3509 - acc: 0.8474 - val_loss: 0.3294 - val_acc: 0.8648\n",
            "Epoch 65/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.3484 - acc: 0.8496 - val_loss: 0.3261 - val_acc: 0.8663\n",
            "Epoch 66/500\n",
            "9463/9463 [==============================] - 0s 13us/step - loss: 0.3497 - acc: 0.8534 - val_loss: 0.3285 - val_acc: 0.8700\n",
            "Epoch 67/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.3388 - acc: 0.8582 - val_loss: 0.3268 - val_acc: 0.8670\n",
            "Epoch 68/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.3412 - acc: 0.8559 - val_loss: 0.3186 - val_acc: 0.8717\n",
            "Epoch 69/500\n",
            "9463/9463 [==============================] - 0s 14us/step - loss: 0.3356 - acc: 0.8542 - val_loss: 0.3185 - val_acc: 0.8723\n",
            "Epoch 70/500\n",
            "9463/9463 [==============================] - 0s 13us/step - loss: 0.3360 - acc: 0.8576 - val_loss: 0.3205 - val_acc: 0.8700\n",
            "Epoch 71/500\n",
            "9463/9463 [==============================] - 0s 13us/step - loss: 0.3330 - acc: 0.8615 - val_loss: 0.3081 - val_acc: 0.8796\n",
            "Epoch 72/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.3253 - acc: 0.8638 - val_loss: 0.3103 - val_acc: 0.8811\n",
            "Epoch 73/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.3291 - acc: 0.8628 - val_loss: 0.3110 - val_acc: 0.8738\n",
            "Epoch 74/500\n",
            "9463/9463 [==============================] - 0s 13us/step - loss: 0.3241 - acc: 0.8628 - val_loss: 0.3012 - val_acc: 0.8818\n",
            "Epoch 75/500\n",
            "9463/9463 [==============================] - 0s 13us/step - loss: 0.3274 - acc: 0.8606 - val_loss: 0.3015 - val_acc: 0.8781\n",
            "Epoch 76/500\n",
            "9463/9463 [==============================] - 0s 14us/step - loss: 0.3207 - acc: 0.8656 - val_loss: 0.2946 - val_acc: 0.8820\n",
            "Epoch 77/500\n",
            "9463/9463 [==============================] - 0s 13us/step - loss: 0.3202 - acc: 0.8661 - val_loss: 0.3099 - val_acc: 0.8794\n",
            "Epoch 78/500\n",
            "9463/9463 [==============================] - 0s 14us/step - loss: 0.3215 - acc: 0.8652 - val_loss: 0.2939 - val_acc: 0.8809\n",
            "Epoch 79/500\n",
            "9463/9463 [==============================] - 0s 13us/step - loss: 0.3178 - acc: 0.8653 - val_loss: 0.2958 - val_acc: 0.8781\n",
            "Epoch 80/500\n",
            "9463/9463 [==============================] - 0s 13us/step - loss: 0.3140 - acc: 0.8667 - val_loss: 0.2899 - val_acc: 0.8865\n",
            "Epoch 81/500\n",
            "9463/9463 [==============================] - 0s 13us/step - loss: 0.3092 - acc: 0.8725 - val_loss: 0.2913 - val_acc: 0.8837\n",
            "Epoch 82/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.3130 - acc: 0.8671 - val_loss: 0.2908 - val_acc: 0.8788\n",
            "Epoch 83/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.3094 - acc: 0.8696 - val_loss: 0.2886 - val_acc: 0.8826\n",
            "Epoch 84/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.3151 - acc: 0.8692 - val_loss: 0.3013 - val_acc: 0.8786\n",
            "Epoch 85/500\n",
            "9463/9463 [==============================] - 0s 13us/step - loss: 0.3106 - acc: 0.8648 - val_loss: 0.2985 - val_acc: 0.8764\n",
            "Epoch 86/500\n",
            "9463/9463 [==============================] - 0s 14us/step - loss: 0.3068 - acc: 0.8702 - val_loss: 0.2807 - val_acc: 0.8859\n",
            "Epoch 87/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.2999 - acc: 0.8732 - val_loss: 0.2911 - val_acc: 0.8824\n",
            "Epoch 88/500\n",
            "9463/9463 [==============================] - 0s 13us/step - loss: 0.2958 - acc: 0.8754 - val_loss: 0.2784 - val_acc: 0.8869\n",
            "Epoch 89/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.2941 - acc: 0.8783 - val_loss: 0.2714 - val_acc: 0.8897\n",
            "Epoch 90/500\n",
            "9463/9463 [==============================] - 0s 13us/step - loss: 0.2939 - acc: 0.8746 - val_loss: 0.2739 - val_acc: 0.8891\n",
            "Epoch 91/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.2888 - acc: 0.8811 - val_loss: 0.2702 - val_acc: 0.8925\n",
            "Epoch 92/500\n",
            "9463/9463 [==============================] - 0s 13us/step - loss: 0.2830 - acc: 0.8809 - val_loss: 0.2771 - val_acc: 0.8889\n",
            "Epoch 93/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.2935 - acc: 0.8759 - val_loss: 0.2684 - val_acc: 0.8923\n",
            "Epoch 94/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.2856 - acc: 0.8808 - val_loss: 0.2728 - val_acc: 0.8871\n",
            "Epoch 95/500\n",
            "9463/9463 [==============================] - 0s 14us/step - loss: 0.2841 - acc: 0.8784 - val_loss: 0.2683 - val_acc: 0.8910\n",
            "Epoch 96/500\n",
            "9463/9463 [==============================] - 0s 13us/step - loss: 0.2891 - acc: 0.8795 - val_loss: 0.2686 - val_acc: 0.8899\n",
            "Epoch 97/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.2736 - acc: 0.8858 - val_loss: 0.2598 - val_acc: 0.8934\n",
            "Epoch 98/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.2807 - acc: 0.8857 - val_loss: 0.2649 - val_acc: 0.8919\n",
            "Epoch 99/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.2886 - acc: 0.8817 - val_loss: 0.2649 - val_acc: 0.8908\n",
            "Epoch 100/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.2796 - acc: 0.8805 - val_loss: 0.2604 - val_acc: 0.8959\n",
            "Epoch 101/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.2825 - acc: 0.8827 - val_loss: 0.2605 - val_acc: 0.8889\n",
            "Epoch 102/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.2773 - acc: 0.8826 - val_loss: 0.2621 - val_acc: 0.8906\n",
            "Epoch 103/500\n",
            "9463/9463 [==============================] - 0s 14us/step - loss: 0.2811 - acc: 0.8795 - val_loss: 0.2616 - val_acc: 0.8949\n",
            "Epoch 104/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.2859 - acc: 0.8838 - val_loss: 0.2620 - val_acc: 0.8904\n",
            "Epoch 105/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.2730 - acc: 0.8851 - val_loss: 0.2567 - val_acc: 0.8942\n",
            "Epoch 106/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2649 - acc: 0.8905 - val_loss: 0.2560 - val_acc: 0.8996\n",
            "Epoch 107/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2724 - acc: 0.8839 - val_loss: 0.2574 - val_acc: 0.8944\n",
            "Epoch 108/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2700 - acc: 0.8869 - val_loss: 0.2549 - val_acc: 0.8936\n",
            "Epoch 109/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2639 - acc: 0.8882 - val_loss: 0.2519 - val_acc: 0.8947\n",
            "Epoch 110/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2712 - acc: 0.8867 - val_loss: 0.2528 - val_acc: 0.8983\n",
            "Epoch 111/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.2661 - acc: 0.8867 - val_loss: 0.2498 - val_acc: 0.8959\n",
            "Epoch 112/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2642 - acc: 0.8912 - val_loss: 0.2527 - val_acc: 0.8953\n",
            "Epoch 113/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.2656 - acc: 0.8881 - val_loss: 0.2491 - val_acc: 0.8987\n",
            "Epoch 114/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.2617 - acc: 0.8935 - val_loss: 0.2563 - val_acc: 0.8919\n",
            "Epoch 115/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2649 - acc: 0.8895 - val_loss: 0.2460 - val_acc: 0.9015\n",
            "Epoch 116/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2599 - acc: 0.8915 - val_loss: 0.2514 - val_acc: 0.8955\n",
            "Epoch 117/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2640 - acc: 0.8924 - val_loss: 0.2612 - val_acc: 0.8889\n",
            "Epoch 118/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2580 - acc: 0.8907 - val_loss: 0.2389 - val_acc: 0.9035\n",
            "Epoch 119/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.2538 - acc: 0.8944 - val_loss: 0.2461 - val_acc: 0.9009\n",
            "Epoch 120/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2465 - acc: 0.8963 - val_loss: 0.2384 - val_acc: 0.8989\n",
            "Epoch 121/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2474 - acc: 0.8968 - val_loss: 0.2565 - val_acc: 0.8938\n",
            "Epoch 122/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2607 - acc: 0.8875 - val_loss: 0.2446 - val_acc: 0.8998\n",
            "Epoch 123/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.2598 - acc: 0.8927 - val_loss: 0.2576 - val_acc: 0.8908\n",
            "Epoch 124/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.2600 - acc: 0.8884 - val_loss: 0.2417 - val_acc: 0.9000\n",
            "Epoch 125/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2485 - acc: 0.8965 - val_loss: 0.2347 - val_acc: 0.9050\n",
            "Epoch 126/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2474 - acc: 0.8950 - val_loss: 0.2482 - val_acc: 0.8964\n",
            "Epoch 127/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2469 - acc: 0.8965 - val_loss: 0.2384 - val_acc: 0.8996\n",
            "Epoch 128/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2464 - acc: 0.8960 - val_loss: 0.2411 - val_acc: 0.9007\n",
            "Epoch 129/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.2465 - acc: 0.8976 - val_loss: 0.2419 - val_acc: 0.8979\n",
            "Epoch 130/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2487 - acc: 0.8987 - val_loss: 0.2317 - val_acc: 0.9035\n",
            "Epoch 131/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2454 - acc: 0.8982 - val_loss: 0.2446 - val_acc: 0.8959\n",
            "Epoch 132/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2474 - acc: 0.8946 - val_loss: 0.2283 - val_acc: 0.9065\n",
            "Epoch 133/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.2393 - acc: 0.9008 - val_loss: 0.2429 - val_acc: 0.8979\n",
            "Epoch 134/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.2432 - acc: 0.8949 - val_loss: 0.2264 - val_acc: 0.9032\n",
            "Epoch 135/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.2426 - acc: 0.8990 - val_loss: 0.2366 - val_acc: 0.8989\n",
            "Epoch 136/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2375 - acc: 0.9012 - val_loss: 0.2568 - val_acc: 0.8917\n",
            "Epoch 137/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2456 - acc: 0.8946 - val_loss: 0.2253 - val_acc: 0.9039\n",
            "Epoch 138/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2427 - acc: 0.8979 - val_loss: 0.2274 - val_acc: 0.9069\n",
            "Epoch 139/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2426 - acc: 0.8972 - val_loss: 0.2254 - val_acc: 0.9073\n",
            "Epoch 140/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2359 - acc: 0.8994 - val_loss: 0.2247 - val_acc: 0.9086\n",
            "Epoch 141/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2339 - acc: 0.9009 - val_loss: 0.2398 - val_acc: 0.9000\n",
            "Epoch 142/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2501 - acc: 0.8920 - val_loss: 0.2375 - val_acc: 0.8974\n",
            "Epoch 143/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2421 - acc: 0.8990 - val_loss: 0.2361 - val_acc: 0.9005\n",
            "Epoch 144/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2384 - acc: 0.8999 - val_loss: 0.2303 - val_acc: 0.9007\n",
            "Epoch 145/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.2395 - acc: 0.9000 - val_loss: 0.2187 - val_acc: 0.9069\n",
            "Epoch 146/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2337 - acc: 0.9025 - val_loss: 0.2356 - val_acc: 0.8979\n",
            "Epoch 147/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2287 - acc: 0.9051 - val_loss: 0.2190 - val_acc: 0.9075\n",
            "Epoch 148/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2264 - acc: 0.9020 - val_loss: 0.2208 - val_acc: 0.9110\n",
            "Epoch 149/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2339 - acc: 0.9030 - val_loss: 0.2302 - val_acc: 0.9032\n",
            "Epoch 150/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.2319 - acc: 0.9001 - val_loss: 0.2210 - val_acc: 0.9082\n",
            "Epoch 151/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.2270 - acc: 0.9057 - val_loss: 0.2198 - val_acc: 0.9065\n",
            "Epoch 152/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2243 - acc: 0.9048 - val_loss: 0.2144 - val_acc: 0.9116\n",
            "Epoch 153/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2301 - acc: 0.8994 - val_loss: 0.2199 - val_acc: 0.9071\n",
            "Epoch 154/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2270 - acc: 0.9064 - val_loss: 0.2191 - val_acc: 0.9045\n",
            "Epoch 155/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2271 - acc: 0.9034 - val_loss: 0.2279 - val_acc: 0.9035\n",
            "Epoch 156/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2361 - acc: 0.9047 - val_loss: 0.2145 - val_acc: 0.9092\n",
            "Epoch 157/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.2236 - acc: 0.9061 - val_loss: 0.2169 - val_acc: 0.9112\n",
            "Epoch 158/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.2233 - acc: 0.9055 - val_loss: 0.2104 - val_acc: 0.9129\n",
            "Epoch 159/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.2283 - acc: 0.9038 - val_loss: 0.2133 - val_acc: 0.9112\n",
            "Epoch 160/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2180 - acc: 0.9101 - val_loss: 0.2290 - val_acc: 0.9022\n",
            "Epoch 161/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.2140 - acc: 0.9098 - val_loss: 0.2163 - val_acc: 0.9131\n",
            "Epoch 162/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.2211 - acc: 0.9089 - val_loss: 0.2193 - val_acc: 0.9090\n",
            "Epoch 163/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2189 - acc: 0.9106 - val_loss: 0.2176 - val_acc: 0.9088\n",
            "Epoch 164/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2095 - acc: 0.9135 - val_loss: 0.2067 - val_acc: 0.9170\n",
            "Epoch 165/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2111 - acc: 0.9139 - val_loss: 0.2113 - val_acc: 0.9170\n",
            "Epoch 166/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2118 - acc: 0.9139 - val_loss: 0.2136 - val_acc: 0.9180\n",
            "Epoch 167/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.2221 - acc: 0.9084 - val_loss: 0.2336 - val_acc: 0.9047\n",
            "Epoch 168/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2248 - acc: 0.9062 - val_loss: 0.2192 - val_acc: 0.9077\n",
            "Epoch 169/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2215 - acc: 0.9092 - val_loss: 0.2134 - val_acc: 0.9155\n",
            "Epoch 170/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2177 - acc: 0.9123 - val_loss: 0.2179 - val_acc: 0.9105\n",
            "Epoch 171/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.2285 - acc: 0.9062 - val_loss: 0.2109 - val_acc: 0.9161\n",
            "Epoch 172/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.2137 - acc: 0.9116 - val_loss: 0.2151 - val_acc: 0.9148\n",
            "Epoch 173/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2139 - acc: 0.9129 - val_loss: 0.2112 - val_acc: 0.9133\n",
            "Epoch 174/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2068 - acc: 0.9132 - val_loss: 0.2062 - val_acc: 0.9163\n",
            "Epoch 175/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2064 - acc: 0.9148 - val_loss: 0.2027 - val_acc: 0.9185\n",
            "Epoch 176/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.2094 - acc: 0.9127 - val_loss: 0.2072 - val_acc: 0.9172\n",
            "Epoch 177/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2084 - acc: 0.9133 - val_loss: 0.2014 - val_acc: 0.9185\n",
            "Epoch 178/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2086 - acc: 0.9142 - val_loss: 0.2014 - val_acc: 0.9163\n",
            "Epoch 179/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.2106 - acc: 0.9128 - val_loss: 0.2016 - val_acc: 0.9185\n",
            "Epoch 180/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.2121 - acc: 0.9135 - val_loss: 0.2180 - val_acc: 0.9103\n",
            "Epoch 181/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2016 - acc: 0.9188 - val_loss: 0.2046 - val_acc: 0.9168\n",
            "Epoch 182/500\n",
            "9463/9463 [==============================] - 0s 13us/step - loss: 0.2088 - acc: 0.9113 - val_loss: 0.2067 - val_acc: 0.9176\n",
            "Epoch 183/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2021 - acc: 0.9163 - val_loss: 0.2055 - val_acc: 0.9191\n",
            "Epoch 184/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2044 - acc: 0.9148 - val_loss: 0.1998 - val_acc: 0.9200\n",
            "Epoch 185/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.2049 - acc: 0.9125 - val_loss: 0.1989 - val_acc: 0.9189\n",
            "Epoch 186/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2037 - acc: 0.9148 - val_loss: 0.2160 - val_acc: 0.9097\n",
            "Epoch 187/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2109 - acc: 0.9102 - val_loss: 0.2034 - val_acc: 0.9159\n",
            "Epoch 188/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.2051 - acc: 0.9158 - val_loss: 0.2076 - val_acc: 0.9155\n",
            "Epoch 189/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2071 - acc: 0.9145 - val_loss: 0.1970 - val_acc: 0.9206\n",
            "Epoch 190/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2132 - acc: 0.9106 - val_loss: 0.2020 - val_acc: 0.9193\n",
            "Epoch 191/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2036 - acc: 0.9174 - val_loss: 0.2070 - val_acc: 0.9142\n",
            "Epoch 192/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.2020 - acc: 0.9193 - val_loss: 0.1983 - val_acc: 0.9191\n",
            "Epoch 193/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1973 - acc: 0.9183 - val_loss: 0.1949 - val_acc: 0.9221\n",
            "Epoch 194/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2002 - acc: 0.9181 - val_loss: 0.2006 - val_acc: 0.9185\n",
            "Epoch 195/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1944 - acc: 0.9214 - val_loss: 0.2119 - val_acc: 0.9114\n",
            "Epoch 196/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.2105 - acc: 0.9129 - val_loss: 0.1953 - val_acc: 0.9195\n",
            "Epoch 197/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2052 - acc: 0.9162 - val_loss: 0.1989 - val_acc: 0.9165\n",
            "Epoch 198/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2001 - acc: 0.9163 - val_loss: 0.1947 - val_acc: 0.9228\n",
            "Epoch 199/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1978 - acc: 0.9189 - val_loss: 0.1977 - val_acc: 0.9185\n",
            "Epoch 200/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1924 - acc: 0.9212 - val_loss: 0.2027 - val_acc: 0.9183\n",
            "Epoch 201/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1951 - acc: 0.9194 - val_loss: 0.2037 - val_acc: 0.9176\n",
            "Epoch 202/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.1929 - acc: 0.9203 - val_loss: 0.1944 - val_acc: 0.9215\n",
            "Epoch 203/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1965 - acc: 0.9164 - val_loss: 0.1960 - val_acc: 0.9198\n",
            "Epoch 204/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1961 - acc: 0.9191 - val_loss: 0.1997 - val_acc: 0.9185\n",
            "Epoch 205/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1964 - acc: 0.9181 - val_loss: 0.1996 - val_acc: 0.9210\n",
            "Epoch 206/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.2039 - acc: 0.9142 - val_loss: 0.2030 - val_acc: 0.9178\n",
            "Epoch 207/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1980 - acc: 0.9174 - val_loss: 0.1979 - val_acc: 0.9238\n",
            "Epoch 208/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1918 - acc: 0.9205 - val_loss: 0.1993 - val_acc: 0.9195\n",
            "Epoch 209/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1978 - acc: 0.9199 - val_loss: 0.1964 - val_acc: 0.9232\n",
            "Epoch 210/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1968 - acc: 0.9212 - val_loss: 0.1933 - val_acc: 0.9232\n",
            "Epoch 211/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1928 - acc: 0.9212 - val_loss: 0.2066 - val_acc: 0.9135\n",
            "Epoch 212/500\n",
            "9463/9463 [==============================] - 0s 13us/step - loss: 0.1887 - acc: 0.9181 - val_loss: 0.1966 - val_acc: 0.9230\n",
            "Epoch 213/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1922 - acc: 0.9187 - val_loss: 0.1904 - val_acc: 0.9247\n",
            "Epoch 214/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1859 - acc: 0.9216 - val_loss: 0.1906 - val_acc: 0.9228\n",
            "Epoch 215/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1830 - acc: 0.9245 - val_loss: 0.1971 - val_acc: 0.9191\n",
            "Epoch 216/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1852 - acc: 0.9210 - val_loss: 0.1914 - val_acc: 0.9245\n",
            "Epoch 217/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1907 - acc: 0.9238 - val_loss: 0.1975 - val_acc: 0.9208\n",
            "Epoch 218/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1895 - acc: 0.9224 - val_loss: 0.2029 - val_acc: 0.9200\n",
            "Epoch 219/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1964 - acc: 0.9196 - val_loss: 0.1892 - val_acc: 0.9260\n",
            "Epoch 220/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1899 - acc: 0.9224 - val_loss: 0.1938 - val_acc: 0.9234\n",
            "Epoch 221/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1849 - acc: 0.9223 - val_loss: 0.1947 - val_acc: 0.9191\n",
            "Epoch 222/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1898 - acc: 0.9213 - val_loss: 0.1899 - val_acc: 0.9283\n",
            "Epoch 223/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1938 - acc: 0.9204 - val_loss: 0.1927 - val_acc: 0.9210\n",
            "Epoch 224/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1826 - acc: 0.9232 - val_loss: 0.1865 - val_acc: 0.9273\n",
            "Epoch 225/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1897 - acc: 0.9235 - val_loss: 0.1875 - val_acc: 0.9288\n",
            "Epoch 226/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1912 - acc: 0.9211 - val_loss: 0.1970 - val_acc: 0.9189\n",
            "Epoch 227/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1874 - acc: 0.9215 - val_loss: 0.2019 - val_acc: 0.9172\n",
            "Epoch 228/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1927 - acc: 0.9217 - val_loss: 0.2028 - val_acc: 0.9191\n",
            "Epoch 229/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1880 - acc: 0.9219 - val_loss: 0.1876 - val_acc: 0.9266\n",
            "Epoch 230/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1865 - acc: 0.9253 - val_loss: 0.1954 - val_acc: 0.9219\n",
            "Epoch 231/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1805 - acc: 0.9261 - val_loss: 0.1959 - val_acc: 0.9251\n",
            "Epoch 232/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1827 - acc: 0.9211 - val_loss: 0.1941 - val_acc: 0.9234\n",
            "Epoch 233/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1854 - acc: 0.9232 - val_loss: 0.1920 - val_acc: 0.9198\n",
            "Epoch 234/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1928 - acc: 0.9211 - val_loss: 0.1900 - val_acc: 0.9281\n",
            "Epoch 235/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1809 - acc: 0.9268 - val_loss: 0.1842 - val_acc: 0.9298\n",
            "Epoch 236/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1807 - acc: 0.9287 - val_loss: 0.2022 - val_acc: 0.9168\n",
            "Epoch 237/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1893 - acc: 0.9207 - val_loss: 0.1840 - val_acc: 0.9320\n",
            "Epoch 238/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1762 - acc: 0.9278 - val_loss: 0.1857 - val_acc: 0.9292\n",
            "Epoch 239/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1806 - acc: 0.9251 - val_loss: 0.1910 - val_acc: 0.9271\n",
            "Epoch 240/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1847 - acc: 0.9269 - val_loss: 0.1822 - val_acc: 0.9268\n",
            "Epoch 241/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.1837 - acc: 0.9258 - val_loss: 0.1858 - val_acc: 0.9275\n",
            "Epoch 242/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1833 - acc: 0.9223 - val_loss: 0.2004 - val_acc: 0.9189\n",
            "Epoch 243/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1837 - acc: 0.9259 - val_loss: 0.1987 - val_acc: 0.9204\n",
            "Epoch 244/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1854 - acc: 0.9241 - val_loss: 0.1865 - val_acc: 0.9283\n",
            "Epoch 245/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1837 - acc: 0.9251 - val_loss: 0.1878 - val_acc: 0.9247\n",
            "Epoch 246/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1738 - acc: 0.9314 - val_loss: 0.1843 - val_acc: 0.9292\n",
            "Epoch 247/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1811 - acc: 0.9211 - val_loss: 0.1878 - val_acc: 0.9219\n",
            "Epoch 248/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1802 - acc: 0.9263 - val_loss: 0.1991 - val_acc: 0.9189\n",
            "Epoch 249/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1783 - acc: 0.9263 - val_loss: 0.1851 - val_acc: 0.9277\n",
            "Epoch 250/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1743 - acc: 0.9278 - val_loss: 0.1938 - val_acc: 0.9210\n",
            "Epoch 251/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.1817 - acc: 0.9266 - val_loss: 0.1928 - val_acc: 0.9275\n",
            "Epoch 252/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1884 - acc: 0.9225 - val_loss: 0.2037 - val_acc: 0.9191\n",
            "Epoch 253/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1728 - acc: 0.9284 - val_loss: 0.1826 - val_acc: 0.9290\n",
            "Epoch 254/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1798 - acc: 0.9248 - val_loss: 0.1807 - val_acc: 0.9305\n",
            "Epoch 255/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1840 - acc: 0.9238 - val_loss: 0.1894 - val_acc: 0.9249\n",
            "Epoch 256/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1757 - acc: 0.9258 - val_loss: 0.1856 - val_acc: 0.9253\n",
            "Epoch 257/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1807 - acc: 0.9262 - val_loss: 0.1809 - val_acc: 0.9298\n",
            "Epoch 258/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1722 - acc: 0.9289 - val_loss: 0.1858 - val_acc: 0.9253\n",
            "Epoch 259/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1744 - acc: 0.9274 - val_loss: 0.1989 - val_acc: 0.9206\n",
            "Epoch 260/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1745 - acc: 0.9307 - val_loss: 0.1843 - val_acc: 0.9303\n",
            "Epoch 261/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.1705 - acc: 0.9287 - val_loss: 0.1857 - val_acc: 0.9258\n",
            "Epoch 262/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1702 - acc: 0.9298 - val_loss: 0.1994 - val_acc: 0.9202\n",
            "Epoch 263/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1716 - acc: 0.9284 - val_loss: 0.1907 - val_acc: 0.9243\n",
            "Epoch 264/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1766 - acc: 0.9265 - val_loss: 0.1840 - val_acc: 0.9275\n",
            "Epoch 265/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1773 - acc: 0.9268 - val_loss: 0.1895 - val_acc: 0.9286\n",
            "Epoch 266/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1884 - acc: 0.9245 - val_loss: 0.1868 - val_acc: 0.9279\n",
            "Epoch 267/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1872 - acc: 0.9269 - val_loss: 0.2015 - val_acc: 0.9219\n",
            "Epoch 268/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1771 - acc: 0.9292 - val_loss: 0.1810 - val_acc: 0.9318\n",
            "Epoch 269/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1767 - acc: 0.9274 - val_loss: 0.1865 - val_acc: 0.9292\n",
            "Epoch 270/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.1786 - acc: 0.9279 - val_loss: 0.1844 - val_acc: 0.9258\n",
            "Epoch 271/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.1705 - acc: 0.9297 - val_loss: 0.1998 - val_acc: 0.9245\n",
            "Epoch 272/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1743 - acc: 0.9315 - val_loss: 0.1885 - val_acc: 0.9275\n",
            "Epoch 273/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1774 - acc: 0.9266 - val_loss: 0.1901 - val_acc: 0.9247\n",
            "Epoch 274/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1748 - acc: 0.9303 - val_loss: 0.1886 - val_acc: 0.9249\n",
            "Epoch 275/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1694 - acc: 0.9301 - val_loss: 0.1855 - val_acc: 0.9301\n",
            "Epoch 276/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1677 - acc: 0.9311 - val_loss: 0.1875 - val_acc: 0.9290\n",
            "Epoch 277/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1695 - acc: 0.9291 - val_loss: 0.1940 - val_acc: 0.9238\n",
            "Epoch 278/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1714 - acc: 0.9297 - val_loss: 0.1915 - val_acc: 0.9277\n",
            "Epoch 279/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1729 - acc: 0.9312 - val_loss: 0.1926 - val_acc: 0.9247\n",
            "Epoch 280/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1744 - acc: 0.9288 - val_loss: 0.1998 - val_acc: 0.9228\n",
            "Epoch 281/500\n",
            "9463/9463 [==============================] - 0s 13us/step - loss: 0.1684 - acc: 0.9318 - val_loss: 0.1838 - val_acc: 0.9290\n",
            "Epoch 282/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1647 - acc: 0.9357 - val_loss: 0.1820 - val_acc: 0.9313\n",
            "Epoch 283/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1654 - acc: 0.9336 - val_loss: 0.1947 - val_acc: 0.9271\n",
            "Epoch 284/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1685 - acc: 0.9300 - val_loss: 0.1840 - val_acc: 0.9313\n",
            "Epoch 285/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1651 - acc: 0.9325 - val_loss: 0.1927 - val_acc: 0.9277\n",
            "Epoch 286/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1700 - acc: 0.9305 - val_loss: 0.1859 - val_acc: 0.9268\n",
            "Epoch 287/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1704 - acc: 0.9327 - val_loss: 0.1917 - val_acc: 0.9266\n",
            "Epoch 288/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1758 - acc: 0.9274 - val_loss: 0.1744 - val_acc: 0.9363\n",
            "Epoch 289/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1732 - acc: 0.9290 - val_loss: 0.1940 - val_acc: 0.9225\n",
            "Epoch 290/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1727 - acc: 0.9268 - val_loss: 0.1994 - val_acc: 0.9193\n",
            "Epoch 291/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.1700 - acc: 0.9306 - val_loss: 0.1979 - val_acc: 0.9232\n",
            "Epoch 292/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1760 - acc: 0.9276 - val_loss: 0.1777 - val_acc: 0.9361\n",
            "Epoch 293/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1810 - acc: 0.9284 - val_loss: 0.1847 - val_acc: 0.9318\n",
            "Epoch 294/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1762 - acc: 0.9265 - val_loss: 0.1922 - val_acc: 0.9268\n",
            "Epoch 295/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1698 - acc: 0.9285 - val_loss: 0.1788 - val_acc: 0.9318\n",
            "Epoch 296/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1664 - acc: 0.9323 - val_loss: 0.1881 - val_acc: 0.9303\n",
            "Epoch 297/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1709 - acc: 0.9316 - val_loss: 0.1849 - val_acc: 0.9311\n",
            "Epoch 298/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1670 - acc: 0.9336 - val_loss: 0.2018 - val_acc: 0.9202\n",
            "Epoch 299/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1652 - acc: 0.9331 - val_loss: 0.1784 - val_acc: 0.9320\n",
            "Epoch 300/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1667 - acc: 0.9322 - val_loss: 0.1779 - val_acc: 0.9341\n",
            "Epoch 301/500\n",
            "9463/9463 [==============================] - 0s 13us/step - loss: 0.1649 - acc: 0.9324 - val_loss: 0.1802 - val_acc: 0.9322\n",
            "Epoch 302/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1613 - acc: 0.9359 - val_loss: 0.1779 - val_acc: 0.9337\n",
            "Epoch 303/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1621 - acc: 0.9341 - val_loss: 0.1927 - val_acc: 0.9219\n",
            "Epoch 304/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1634 - acc: 0.9315 - val_loss: 0.1809 - val_acc: 0.9359\n",
            "Epoch 305/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1665 - acc: 0.9330 - val_loss: 0.1849 - val_acc: 0.9292\n",
            "Epoch 306/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1574 - acc: 0.9333 - val_loss: 0.1835 - val_acc: 0.9333\n",
            "Epoch 307/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1649 - acc: 0.9325 - val_loss: 0.1835 - val_acc: 0.9298\n",
            "Epoch 308/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1589 - acc: 0.9350 - val_loss: 0.1841 - val_acc: 0.9305\n",
            "Epoch 309/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1668 - acc: 0.9315 - val_loss: 0.1818 - val_acc: 0.9328\n",
            "Epoch 310/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.1627 - acc: 0.9331 - val_loss: 0.1861 - val_acc: 0.9266\n",
            "Epoch 311/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1590 - acc: 0.9336 - val_loss: 0.1813 - val_acc: 0.9324\n",
            "Epoch 312/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1641 - acc: 0.9349 - val_loss: 0.1893 - val_acc: 0.9243\n",
            "Epoch 313/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1615 - acc: 0.9340 - val_loss: 0.1850 - val_acc: 0.9281\n",
            "Epoch 314/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1634 - acc: 0.9317 - val_loss: 0.1840 - val_acc: 0.9324\n",
            "Epoch 315/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1623 - acc: 0.9329 - val_loss: 0.1768 - val_acc: 0.9369\n",
            "Epoch 316/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1675 - acc: 0.9346 - val_loss: 0.1778 - val_acc: 0.9290\n",
            "Epoch 317/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1615 - acc: 0.9378 - val_loss: 0.1793 - val_acc: 0.9341\n",
            "Epoch 318/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1599 - acc: 0.9340 - val_loss: 0.1805 - val_acc: 0.9352\n",
            "Epoch 319/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1604 - acc: 0.9347 - val_loss: 0.1869 - val_acc: 0.9294\n",
            "Epoch 320/500\n",
            "9463/9463 [==============================] - 0s 13us/step - loss: 0.1639 - acc: 0.9332 - val_loss: 0.1876 - val_acc: 0.9286\n",
            "Epoch 321/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1576 - acc: 0.9367 - val_loss: 0.1799 - val_acc: 0.9346\n",
            "Epoch 322/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1680 - acc: 0.9326 - val_loss: 0.1857 - val_acc: 0.9324\n",
            "Epoch 323/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1598 - acc: 0.9342 - val_loss: 0.1773 - val_acc: 0.9313\n",
            "Epoch 324/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1592 - acc: 0.9351 - val_loss: 0.1845 - val_acc: 0.9337\n",
            "Epoch 325/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1645 - acc: 0.9324 - val_loss: 0.1816 - val_acc: 0.9313\n",
            "Epoch 326/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1586 - acc: 0.9368 - val_loss: 0.1771 - val_acc: 0.9341\n",
            "Epoch 327/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1671 - acc: 0.9324 - val_loss: 0.1883 - val_acc: 0.9318\n",
            "Epoch 328/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1570 - acc: 0.9383 - val_loss: 0.1858 - val_acc: 0.9328\n",
            "Epoch 329/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1569 - acc: 0.9374 - val_loss: 0.1777 - val_acc: 0.9356\n",
            "Epoch 330/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.1663 - acc: 0.9333 - val_loss: 0.1902 - val_acc: 0.9324\n",
            "Epoch 331/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1713 - acc: 0.9311 - val_loss: 0.1951 - val_acc: 0.9243\n",
            "Epoch 332/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1627 - acc: 0.9329 - val_loss: 0.1732 - val_acc: 0.9352\n",
            "Epoch 333/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1609 - acc: 0.9361 - val_loss: 0.1832 - val_acc: 0.9318\n",
            "Epoch 334/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1638 - acc: 0.9337 - val_loss: 0.1822 - val_acc: 0.9352\n",
            "Epoch 335/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.1684 - acc: 0.9330 - val_loss: 0.1832 - val_acc: 0.9311\n",
            "Epoch 336/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1618 - acc: 0.9346 - val_loss: 0.1845 - val_acc: 0.9266\n",
            "Epoch 337/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1583 - acc: 0.9359 - val_loss: 0.1821 - val_acc: 0.9281\n",
            "Epoch 338/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1558 - acc: 0.9361 - val_loss: 0.1819 - val_acc: 0.9339\n",
            "Epoch 339/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1626 - acc: 0.9337 - val_loss: 0.1807 - val_acc: 0.9311\n",
            "Epoch 340/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.1623 - acc: 0.9360 - val_loss: 0.1786 - val_acc: 0.9350\n",
            "Epoch 341/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1589 - acc: 0.9341 - val_loss: 0.1767 - val_acc: 0.9361\n",
            "Epoch 342/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1611 - acc: 0.9344 - val_loss: 0.1933 - val_acc: 0.9245\n",
            "Epoch 343/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1653 - acc: 0.9313 - val_loss: 0.1829 - val_acc: 0.9311\n",
            "Epoch 344/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1584 - acc: 0.9371 - val_loss: 0.1923 - val_acc: 0.9262\n",
            "Epoch 345/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1571 - acc: 0.9378 - val_loss: 0.1819 - val_acc: 0.9328\n",
            "Epoch 346/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1573 - acc: 0.9365 - val_loss: 0.1928 - val_acc: 0.9260\n",
            "Epoch 347/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1568 - acc: 0.9384 - val_loss: 0.1904 - val_acc: 0.9301\n",
            "Epoch 348/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1610 - acc: 0.9331 - val_loss: 0.1822 - val_acc: 0.9294\n",
            "Epoch 349/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1626 - acc: 0.9333 - val_loss: 0.1839 - val_acc: 0.9350\n",
            "Epoch 350/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.1660 - acc: 0.9301 - val_loss: 0.1877 - val_acc: 0.9288\n",
            "Epoch 351/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1500 - acc: 0.9393 - val_loss: 0.1732 - val_acc: 0.9348\n",
            "Epoch 352/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1529 - acc: 0.9391 - val_loss: 0.1808 - val_acc: 0.9320\n",
            "Epoch 353/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1548 - acc: 0.9357 - val_loss: 0.1809 - val_acc: 0.9333\n",
            "Epoch 354/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1566 - acc: 0.9372 - val_loss: 0.1823 - val_acc: 0.9296\n",
            "Epoch 355/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1534 - acc: 0.9377 - val_loss: 0.1738 - val_acc: 0.9363\n",
            "Epoch 356/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1565 - acc: 0.9388 - val_loss: 0.1815 - val_acc: 0.9290\n",
            "Epoch 357/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1565 - acc: 0.9373 - val_loss: 0.1842 - val_acc: 0.9322\n",
            "Epoch 358/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1571 - acc: 0.9363 - val_loss: 0.1763 - val_acc: 0.9346\n",
            "Epoch 359/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1497 - acc: 0.9415 - val_loss: 0.1976 - val_acc: 0.9230\n",
            "Epoch 360/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.1570 - acc: 0.9398 - val_loss: 0.1829 - val_acc: 0.9331\n",
            "Epoch 361/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.1544 - acc: 0.9362 - val_loss: 0.1950 - val_acc: 0.9290\n",
            "Epoch 362/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1546 - acc: 0.9393 - val_loss: 0.1895 - val_acc: 0.9281\n",
            "Epoch 363/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1522 - acc: 0.9366 - val_loss: 0.1769 - val_acc: 0.9346\n",
            "Epoch 364/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1576 - acc: 0.9350 - val_loss: 0.1793 - val_acc: 0.9335\n",
            "Epoch 365/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1569 - acc: 0.9368 - val_loss: 0.1782 - val_acc: 0.9298\n",
            "Epoch 366/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1592 - acc: 0.9357 - val_loss: 0.1848 - val_acc: 0.9273\n",
            "Epoch 367/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1585 - acc: 0.9355 - val_loss: 0.1844 - val_acc: 0.9292\n",
            "Epoch 368/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1499 - acc: 0.9379 - val_loss: 0.1835 - val_acc: 0.9311\n",
            "Epoch 369/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1544 - acc: 0.9369 - val_loss: 0.1784 - val_acc: 0.9337\n",
            "Epoch 370/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.1520 - acc: 0.9393 - val_loss: 0.1772 - val_acc: 0.9322\n",
            "Epoch 371/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1617 - acc: 0.9344 - val_loss: 0.1811 - val_acc: 0.9354\n",
            "Epoch 372/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1476 - acc: 0.9406 - val_loss: 0.1858 - val_acc: 0.9326\n",
            "Epoch 373/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1541 - acc: 0.9410 - val_loss: 0.1769 - val_acc: 0.9363\n",
            "Epoch 374/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1461 - acc: 0.9399 - val_loss: 0.1819 - val_acc: 0.9324\n",
            "Epoch 375/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1523 - acc: 0.9384 - val_loss: 0.1874 - val_acc: 0.9296\n",
            "Epoch 376/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1526 - acc: 0.9348 - val_loss: 0.1804 - val_acc: 0.9341\n",
            "Epoch 377/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1524 - acc: 0.9393 - val_loss: 0.1704 - val_acc: 0.9374\n",
            "Epoch 378/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1478 - acc: 0.9382 - val_loss: 0.1746 - val_acc: 0.9363\n",
            "Epoch 379/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1508 - acc: 0.9381 - val_loss: 0.1758 - val_acc: 0.9339\n",
            "Epoch 380/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.1489 - acc: 0.9392 - val_loss: 0.1776 - val_acc: 0.9339\n",
            "Epoch 381/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1493 - acc: 0.9393 - val_loss: 0.1786 - val_acc: 0.9354\n",
            "Epoch 382/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1505 - acc: 0.9397 - val_loss: 0.1875 - val_acc: 0.9320\n",
            "Epoch 383/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1458 - acc: 0.9389 - val_loss: 0.1848 - val_acc: 0.9303\n",
            "Epoch 384/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1574 - acc: 0.9343 - val_loss: 0.1992 - val_acc: 0.9245\n",
            "Epoch 385/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1541 - acc: 0.9347 - val_loss: 0.1780 - val_acc: 0.9352\n",
            "Epoch 386/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1530 - acc: 0.9389 - val_loss: 0.1760 - val_acc: 0.9359\n",
            "Epoch 387/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1533 - acc: 0.9383 - val_loss: 0.1918 - val_acc: 0.9283\n",
            "Epoch 388/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1553 - acc: 0.9338 - val_loss: 0.1758 - val_acc: 0.9363\n",
            "Epoch 389/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1505 - acc: 0.9407 - val_loss: 0.1731 - val_acc: 0.9365\n",
            "Epoch 390/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.1496 - acc: 0.9382 - val_loss: 0.1730 - val_acc: 0.9371\n",
            "Epoch 391/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.1491 - acc: 0.9406 - val_loss: 0.1686 - val_acc: 0.9404\n",
            "Epoch 392/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1527 - acc: 0.9379 - val_loss: 0.1814 - val_acc: 0.9322\n",
            "Epoch 393/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1481 - acc: 0.9385 - val_loss: 0.1763 - val_acc: 0.9324\n",
            "Epoch 394/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1449 - acc: 0.9421 - val_loss: 0.1688 - val_acc: 0.9399\n",
            "Epoch 395/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1584 - acc: 0.9359 - val_loss: 0.1812 - val_acc: 0.9301\n",
            "Epoch 396/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1520 - acc: 0.9363 - val_loss: 0.1756 - val_acc: 0.9337\n",
            "Epoch 397/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1515 - acc: 0.9383 - val_loss: 0.1691 - val_acc: 0.9374\n",
            "Epoch 398/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1551 - acc: 0.9364 - val_loss: 0.2118 - val_acc: 0.9178\n",
            "Epoch 399/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1581 - acc: 0.9360 - val_loss: 0.1747 - val_acc: 0.9369\n",
            "Epoch 400/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1608 - acc: 0.9329 - val_loss: 0.1785 - val_acc: 0.9346\n",
            "Epoch 401/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1576 - acc: 0.9365 - val_loss: 0.1802 - val_acc: 0.9343\n",
            "Epoch 402/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1496 - acc: 0.9401 - val_loss: 0.1772 - val_acc: 0.9346\n",
            "Epoch 403/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1506 - acc: 0.9402 - val_loss: 0.1877 - val_acc: 0.9326\n",
            "Epoch 404/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1464 - acc: 0.9386 - val_loss: 0.1765 - val_acc: 0.9348\n",
            "Epoch 405/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1520 - acc: 0.9388 - val_loss: 0.1780 - val_acc: 0.9365\n",
            "Epoch 406/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1485 - acc: 0.9381 - val_loss: 0.1749 - val_acc: 0.9324\n",
            "Epoch 407/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1479 - acc: 0.9383 - val_loss: 0.1759 - val_acc: 0.9354\n",
            "Epoch 408/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1499 - acc: 0.9397 - val_loss: 0.1833 - val_acc: 0.9320\n",
            "Epoch 409/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1508 - acc: 0.9391 - val_loss: 0.1730 - val_acc: 0.9359\n",
            "Epoch 410/500\n",
            "9463/9463 [==============================] - 0s 13us/step - loss: 0.1566 - acc: 0.9379 - val_loss: 0.1893 - val_acc: 0.9268\n",
            "Epoch 411/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1478 - acc: 0.9408 - val_loss: 0.1884 - val_acc: 0.9288\n",
            "Epoch 412/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1475 - acc: 0.9408 - val_loss: 0.1745 - val_acc: 0.9374\n",
            "Epoch 413/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1526 - acc: 0.9392 - val_loss: 0.1836 - val_acc: 0.9301\n",
            "Epoch 414/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1512 - acc: 0.9378 - val_loss: 0.1811 - val_acc: 0.9316\n",
            "Epoch 415/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1513 - acc: 0.9360 - val_loss: 0.1879 - val_acc: 0.9341\n",
            "Epoch 416/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1646 - acc: 0.9325 - val_loss: 0.1810 - val_acc: 0.9322\n",
            "Epoch 417/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1431 - acc: 0.9416 - val_loss: 0.1732 - val_acc: 0.9348\n",
            "Epoch 418/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1479 - acc: 0.9408 - val_loss: 0.1763 - val_acc: 0.9352\n",
            "Epoch 419/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1474 - acc: 0.9383 - val_loss: 0.1803 - val_acc: 0.9339\n",
            "Epoch 420/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1382 - acc: 0.9437 - val_loss: 0.1697 - val_acc: 0.9393\n",
            "Epoch 421/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1432 - acc: 0.9417 - val_loss: 0.1708 - val_acc: 0.9350\n",
            "Epoch 422/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1481 - acc: 0.9423 - val_loss: 0.2051 - val_acc: 0.9183\n",
            "Epoch 423/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1535 - acc: 0.9372 - val_loss: 0.1754 - val_acc: 0.9369\n",
            "Epoch 424/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1537 - acc: 0.9365 - val_loss: 0.1695 - val_acc: 0.9389\n",
            "Epoch 425/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1513 - acc: 0.9397 - val_loss: 0.1837 - val_acc: 0.9296\n",
            "Epoch 426/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1441 - acc: 0.9414 - val_loss: 0.1891 - val_acc: 0.9286\n",
            "Epoch 427/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1462 - acc: 0.9404 - val_loss: 0.1715 - val_acc: 0.9393\n",
            "Epoch 428/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1495 - acc: 0.9379 - val_loss: 0.1779 - val_acc: 0.9354\n",
            "Epoch 429/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.1472 - acc: 0.9421 - val_loss: 0.1673 - val_acc: 0.9386\n",
            "Epoch 430/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1437 - acc: 0.9417 - val_loss: 0.1863 - val_acc: 0.9273\n",
            "Epoch 431/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1366 - acc: 0.9447 - val_loss: 0.1742 - val_acc: 0.9374\n",
            "Epoch 432/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1451 - acc: 0.9416 - val_loss: 0.1752 - val_acc: 0.9350\n",
            "Epoch 433/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1482 - acc: 0.9408 - val_loss: 0.1760 - val_acc: 0.9371\n",
            "Epoch 434/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1375 - acc: 0.9455 - val_loss: 0.1811 - val_acc: 0.9348\n",
            "Epoch 435/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1525 - acc: 0.9399 - val_loss: 0.1866 - val_acc: 0.9309\n",
            "Epoch 436/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1576 - acc: 0.9360 - val_loss: 0.1738 - val_acc: 0.9331\n",
            "Epoch 437/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1496 - acc: 0.9390 - val_loss: 0.1950 - val_acc: 0.9215\n",
            "Epoch 438/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1556 - acc: 0.9369 - val_loss: 0.1750 - val_acc: 0.9359\n",
            "Epoch 439/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1522 - acc: 0.9383 - val_loss: 0.1823 - val_acc: 0.9326\n",
            "Epoch 440/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1472 - acc: 0.9409 - val_loss: 0.1801 - val_acc: 0.9288\n",
            "Epoch 441/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1515 - acc: 0.9402 - val_loss: 0.1707 - val_acc: 0.9361\n",
            "Epoch 442/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1490 - acc: 0.9424 - val_loss: 0.1885 - val_acc: 0.9262\n",
            "Epoch 443/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1501 - acc: 0.9379 - val_loss: 0.1787 - val_acc: 0.9331\n",
            "Epoch 444/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1394 - acc: 0.9445 - val_loss: 0.1749 - val_acc: 0.9356\n",
            "Epoch 445/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1393 - acc: 0.9440 - val_loss: 0.1771 - val_acc: 0.9343\n",
            "Epoch 446/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1410 - acc: 0.9433 - val_loss: 0.1835 - val_acc: 0.9326\n",
            "Epoch 447/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1415 - acc: 0.9447 - val_loss: 0.1809 - val_acc: 0.9337\n",
            "Epoch 448/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1471 - acc: 0.9410 - val_loss: 0.1765 - val_acc: 0.9333\n",
            "Epoch 449/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.1471 - acc: 0.9401 - val_loss: 0.1868 - val_acc: 0.9273\n",
            "Epoch 450/500\n",
            "9463/9463 [==============================] - 0s 13us/step - loss: 0.1414 - acc: 0.9440 - val_loss: 0.1716 - val_acc: 0.9378\n",
            "Epoch 451/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1416 - acc: 0.9431 - val_loss: 0.1743 - val_acc: 0.9369\n",
            "Epoch 452/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1384 - acc: 0.9454 - val_loss: 0.1743 - val_acc: 0.9380\n",
            "Epoch 453/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1401 - acc: 0.9448 - val_loss: 0.1762 - val_acc: 0.9365\n",
            "Epoch 454/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1461 - acc: 0.9415 - val_loss: 0.1705 - val_acc: 0.9382\n",
            "Epoch 455/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1390 - acc: 0.9440 - val_loss: 0.1815 - val_acc: 0.9318\n",
            "Epoch 456/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1482 - acc: 0.9405 - val_loss: 0.1756 - val_acc: 0.9339\n",
            "Epoch 457/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1380 - acc: 0.9455 - val_loss: 0.1778 - val_acc: 0.9346\n",
            "Epoch 458/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1453 - acc: 0.9421 - val_loss: 0.1727 - val_acc: 0.9378\n",
            "Epoch 459/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.1474 - acc: 0.9438 - val_loss: 0.1769 - val_acc: 0.9328\n",
            "Epoch 460/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1461 - acc: 0.9424 - val_loss: 0.1781 - val_acc: 0.9324\n",
            "Epoch 461/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1507 - acc: 0.9389 - val_loss: 0.1732 - val_acc: 0.9346\n",
            "Epoch 462/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1387 - acc: 0.9439 - val_loss: 0.1736 - val_acc: 0.9356\n",
            "Epoch 463/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1425 - acc: 0.9458 - val_loss: 0.1697 - val_acc: 0.9346\n",
            "Epoch 464/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1413 - acc: 0.9393 - val_loss: 0.1673 - val_acc: 0.9393\n",
            "Epoch 465/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1423 - acc: 0.9412 - val_loss: 0.1762 - val_acc: 0.9378\n",
            "Epoch 466/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1457 - acc: 0.9429 - val_loss: 0.1752 - val_acc: 0.9352\n",
            "Epoch 467/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1426 - acc: 0.9431 - val_loss: 0.1834 - val_acc: 0.9341\n",
            "Epoch 468/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1419 - acc: 0.9433 - val_loss: 0.1732 - val_acc: 0.9391\n",
            "Epoch 469/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.1385 - acc: 0.9459 - val_loss: 0.1788 - val_acc: 0.9354\n",
            "Epoch 470/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1438 - acc: 0.9428 - val_loss: 0.1735 - val_acc: 0.9356\n",
            "Epoch 471/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1389 - acc: 0.9456 - val_loss: 0.1777 - val_acc: 0.9382\n",
            "Epoch 472/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1406 - acc: 0.9441 - val_loss: 0.1899 - val_acc: 0.9320\n",
            "Epoch 473/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1409 - acc: 0.9448 - val_loss: 0.1685 - val_acc: 0.9391\n",
            "Epoch 474/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1410 - acc: 0.9440 - val_loss: 0.1667 - val_acc: 0.9423\n",
            "Epoch 475/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1358 - acc: 0.9460 - val_loss: 0.1831 - val_acc: 0.9298\n",
            "Epoch 476/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1379 - acc: 0.9431 - val_loss: 0.1766 - val_acc: 0.9359\n",
            "Epoch 477/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1476 - acc: 0.9429 - val_loss: 0.1816 - val_acc: 0.9333\n",
            "Epoch 478/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1399 - acc: 0.9429 - val_loss: 0.1809 - val_acc: 0.9337\n",
            "Epoch 479/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.1355 - acc: 0.9479 - val_loss: 0.1696 - val_acc: 0.9399\n",
            "Epoch 480/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1447 - acc: 0.9425 - val_loss: 0.1743 - val_acc: 0.9356\n",
            "Epoch 481/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1420 - acc: 0.9428 - val_loss: 0.1748 - val_acc: 0.9341\n",
            "Epoch 482/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1388 - acc: 0.9430 - val_loss: 0.1732 - val_acc: 0.9382\n",
            "Epoch 483/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1411 - acc: 0.9441 - val_loss: 0.1731 - val_acc: 0.9376\n",
            "Epoch 484/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1401 - acc: 0.9444 - val_loss: 0.1736 - val_acc: 0.9384\n",
            "Epoch 485/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1376 - acc: 0.9452 - val_loss: 0.1704 - val_acc: 0.9378\n",
            "Epoch 486/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1391 - acc: 0.9441 - val_loss: 0.1773 - val_acc: 0.9339\n",
            "Epoch 487/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1370 - acc: 0.9459 - val_loss: 0.1746 - val_acc: 0.9365\n",
            "Epoch 488/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1360 - acc: 0.9447 - val_loss: 0.1742 - val_acc: 0.9382\n",
            "Epoch 489/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1320 - acc: 0.9478 - val_loss: 0.1744 - val_acc: 0.9359\n",
            "Epoch 490/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1295 - acc: 0.9500 - val_loss: 0.1738 - val_acc: 0.9378\n",
            "Epoch 491/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1395 - acc: 0.9446 - val_loss: 0.1744 - val_acc: 0.9363\n",
            "Epoch 492/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1443 - acc: 0.9421 - val_loss: 0.1741 - val_acc: 0.9341\n",
            "Epoch 493/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1417 - acc: 0.9425 - val_loss: 0.1993 - val_acc: 0.9273\n",
            "Epoch 494/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1455 - acc: 0.9423 - val_loss: 0.1962 - val_acc: 0.9258\n",
            "Epoch 495/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1437 - acc: 0.9450 - val_loss: 0.1844 - val_acc: 0.9335\n",
            "Epoch 496/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1457 - acc: 0.9392 - val_loss: 0.1647 - val_acc: 0.9399\n",
            "Epoch 497/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1481 - acc: 0.9384 - val_loss: 0.1856 - val_acc: 0.9324\n",
            "Epoch 498/500\n",
            "9463/9463 [==============================] - 0s 12us/step - loss: 0.1405 - acc: 0.9431 - val_loss: 0.1832 - val_acc: 0.9352\n",
            "Epoch 499/500\n",
            "9463/9463 [==============================] - 0s 11us/step - loss: 0.1476 - acc: 0.9430 - val_loss: 0.1718 - val_acc: 0.9419\n",
            "Epoch 500/500\n",
            "9463/9463 [==============================] - 0s 10us/step - loss: 0.1399 - acc: 0.9460 - val_loss: 0.1732 - val_acc: 0.9395\n",
            "Confusion Matrix:\n",
            "[[1543  133]\n",
            " [  79 1776]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEVCAYAAADpbDJPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f6ff012b438>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEVCAYAAADpbDJPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f6fde241e48>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.94\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
